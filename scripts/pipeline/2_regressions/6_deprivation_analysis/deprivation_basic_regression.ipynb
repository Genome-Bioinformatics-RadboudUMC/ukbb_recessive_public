{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from itertools import product\n",
    "from ukbb_recessive.regression.regressions import run_regressions, save_table_for_paper, get_formula, get_target_family"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccbc08c",
   "metadata": {},
   "source": [
    "# Load regressions datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f6e97",
   "metadata": {},
   "source": [
    "First, we load datasets for the regression analysis saved on the previous step using script `0_create_dataset.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../../../../data/tables\"\n",
    "datasets_path = '.../450k/datasets'\n",
    "\n",
    "datasets_dict = {\n",
    "    # 'Cassa': pd.read_csv(f\"{datasets_path}/Cassa.csv\", sep='\\t'),\n",
    "    # 'pLI': pd.read_csv(f\"{datasets_path}/PLI.csv\", sep='\\t'),\n",
    "    # 'Weghorn': pd.read_csv(f\"{datasets_path}/Weghorn-drift.csv\", sep='\\t'),\n",
    "    'Roulette': pd.read_csv(f\"{datasets_path}/Roulette.csv\", sep='\\t'),\n",
    "}\n",
    "\n",
    "# samples of interest: European & non-related without hom and comp_het\n",
    "european_non_rel_samples = (\n",
    "    \".../450k/samples/european_non_related_no_withdrawal_to_include_450k.no_hom_comp_het.txt\"\n",
    ")\n",
    "\n",
    "with open(european_non_rel_samples, 'r') as f:\n",
    "    european_non_rel_samples = [l.strip() for l in f.readlines()]\n",
    "\n",
    "print (f\"Number of european non-related samples without hom and comp_het: {len(european_non_rel_samples)}\\n\")\n",
    "\n",
    "for dataset_name, dataset in datasets_dict.items():\n",
    "    print (f\"Number of samples in {dataset_name}: {datasets_dict[dataset_name].shape[0]}\")\n",
    "    # dataset = dataset[dataset['eid'].astype(str).isin(european_non_rel_samples)].copy()\n",
    "\n",
    "    # dataset['multiple_deprivation'] = (dataset['multiple_deprivation_engand']\n",
    "    #                                    .combine_first(dataset['multiple_deprivation_wales'])\n",
    "    #                                    .combine_first(dataset['multiple_deprivation_scotland']))\n",
    "    \n",
    "    # datasets_dict[dataset_name] = dataset\n",
    "    \n",
    "    datasets_dict[dataset_name] = dataset[dataset['eid'].astype(str).isin(european_non_rel_samples)].copy()\n",
    "\n",
    "    print (f\"Number of samples in {dataset_name} after filtration: {datasets_dict[dataset_name].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6441b",
   "metadata": {},
   "source": [
    "Here are all s_het-based genetic burdens, calculated based on different gene sets and variants (PLPs or singleton LOFs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7519fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datasets_dict[list(datasets_dict.keys())[0]].columns:\n",
    "    if col[:5] == 's_het':\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns.tolist()[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdbce5",
   "metadata": {},
   "source": [
    "# Define analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = ['multiple_deprivation_engand', 'edu_deprivation_england',\n",
    "              'housing_deprivation_england', 'income_deprivation_england','health_deprivation_england']\n",
    "\n",
    "# we looked into these phenotypes as covariates\n",
    "covariate_deprivation_regressions = {\n",
    "    's_hets': ['s_het_recessive_all', 's_het_lof_without_AR'] + list(product(['s_het_recessive_all', 's_het_lof_without_AR'], covariates)),\n",
    "    'targets': ['childlessness', 'years_of_edu', 'diagnosis_total_ICD10_cnt_log', 'is_blond'],\n",
    "    'families': ['binomial', 'gaussian', 'gaussian', 'binomial'],\n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 10,\n",
    "    'filter_dataset': lambda dataset: dataset[~dataset['multiple_deprivation_engand'].isnull()]\n",
    "}\n",
    "# we looked into id vs rest\n",
    "id_vs_rest_covariate_deprivation_regressions = {\n",
    "    's_hets': ['s_het_recessive_AR_without_ID', 's_het_recessive_ID_total'] + list(product(['s_het_recessive_AR_without_ID', 's_het_recessive_ID_total'], covariates)),\n",
    "    'targets': ['childlessness', 'years_of_edu', 'diagnosis_total_ICD10_cnt_log', 'is_blond'],\n",
    "    'families': ['binomial', 'gaussian', 'gaussian', 'binomial'],\n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 14,\n",
    "    'filter_dataset': lambda dataset: dataset[~dataset['multiple_deprivation_engand'].isnull()]\n",
    "}\n",
    "\n",
    "analyses = {\n",
    "    # 'covariate_deprivation': covariate_deprivation_regressions,\n",
    "    'id_vs_rest_covariate_deprivation': id_vs_rest_covariate_deprivation_regressions\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619c697",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e20751",
   "metadata": {},
   "outputs": [],
   "source": [
    "for analysis, analysis_cfg in analyses.items():\n",
    "\n",
    "    all_results = defaultdict(list)\n",
    "\n",
    "    print (f\"Running {analysis} analysis\\n\")\n",
    "\n",
    "    # read analysis config\n",
    "    s_hets = analysis_cfg['s_hets']\n",
    "    targets = analysis_cfg['targets']\n",
    "    families = analysis_cfg['families']\n",
    "    genders = analysis_cfg['genders']   \n",
    "    filter_dataset_func = analysis_cfg['filter_dataset']\n",
    "    n_tests_correction = analysis_cfg['n_tests_correction']\n",
    "     \n",
    "    \n",
    "    # iterate over different s-het datasets\n",
    "    for dataset_key in datasets_dict:\n",
    "        print (\"\\tProcessing\", dataset_key, flush=True)\n",
    "\n",
    "        # iterate over different s-het burdens\n",
    "        for s_het in s_hets:\n",
    "            if not (isinstance(s_het, list) or isinstance(s_het, tuple)) :\n",
    "                s_het = [s_het]\n",
    "\n",
    "            analysis_tag = f'{analysis} regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "            print (f\"\\t\\tRun {analysis_tag}\")\n",
    "\n",
    "            dataset = filter_dataset_func(datasets_dict[dataset_key]).copy()\n",
    "            print (f\"\\t\\t\\tDataset size after filtration: {dataset.shape}\")\n",
    "\n",
    "            regression_result = run_regressions(dataset=dataset, \n",
    "                                                targets=targets, \n",
    "                                                families=families, \n",
    "                                                analysis_tag=analysis_tag, \n",
    "                                                genders=genders, \n",
    "                                                s_het_list=s_het, \n",
    "                                                tab_offset='\\t\\t\\t', \n",
    "                                                n_tests_correction=n_tests_correction)\n",
    "            \n",
    "            all_results[dataset_key].append(regression_result)\n",
    "\n",
    "            print()\n",
    "\n",
    "    all_results = {dataset_key: pd.concat(all_results[dataset_key]) for dataset_key in all_results}\n",
    "\n",
    "    save_table_for_paper(all_results, f\"{output_path}/table_{analysis}_analysis.xlsx\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lah ../../../../data/tables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "variant_prio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
