{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from ukbb_recessive.data_collection.variants import VariantFeatures\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select rare synonymous variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '.../450k/plp_selection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range (1, 23)):\n",
    "    input_file = f\"{path}/chr{i}_1929_genes_annotated.txt\"\n",
    "    output_file = f\"{path}/synonymous_rare/chr{i}_total_presumable_plps.txt\"\n",
    "    \n",
    "    df = pd.read_csv(input_file, low_memory=False,\n",
    "                     sep='\\t')\n",
    "    df_syn = df[\n",
    "        df['synonymous'] & \n",
    "        (df['hets'] <= 20) &\n",
    "        (df['homs'] <= 0)  \n",
    "    ]\n",
    "        \n",
    "    df_syn.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print (\"Synonymous data filtered!\", flush=True)\n",
    "\n",
    "result = []\n",
    "for i in tqdm.tqdm(range (1, 23)):\n",
    "    plp_file = f\"{path}/synonymous_rare/chr{i}_total_presumable_plps.txt\"\n",
    "    \n",
    "    result.append(pd.read_csv(plp_file, sep='\\t'))\n",
    "\n",
    "result = pd.concat(result)\n",
    "result.sort_values(by=['chr', 'position'])\n",
    "\n",
    "result.to_csv(f\"{path}/synonymous_rare/all_chr_total_presumable_plps_HFE_final_sorted.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l .../450k/plp_selection/synonymous_rare/all_chr_total_presumable_plps_HFE_final_sorted.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter synonymous variants in cohort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original files with samples variants generated in RAP per chromosome\n",
    "rap_files = glob.glob(\".../450k/RAP_output_per_chr/*.all_parts_final.csv\")\n",
    "\n",
    "## file, that contains all PLPs found in the cohort\n",
    "all_plps_file = (\n",
    "    \".../450k/plp_selection/synonymous_rare/all_chr_total_presumable_plps_HFE_final_sorted.txt\"\n",
    ")\n",
    "\n",
    "# output folder for PLPs\n",
    "## bugfix with gnomad frequency -- now in %\n",
    "output_folder= '.../450k/RAP_output_per_chr/filtered_plps/synonymous_rare'\n",
    "\n",
    "\n",
    "# create output folder if not exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out non-PLP variants for every chromosome\n",
    "\n",
    "VariantFeatures().filter_plps_in_samples(\n",
    "    rap_files = rap_files, \n",
    "    output_folder = output_folder, \n",
    "    all_plps_file = all_plps_file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample synonymous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plps = (\".../450k/plp_selection/basic/new_gene_names/\"\n",
    "        \"new_freq/new_relatedness/all_chr_total_presumable_plps_HFE_final_sorted.txt\"\n",
    ")\n",
    "plps = pd.read_csv(plps, sep='\\t')\n",
    "plps = plps[(plps['hets'] <= 20) & (plps['homs'] <= 0)]\n",
    "\n",
    "print (\"Number of PLPs for regressions:\", plps.shape[0])\n",
    "\n",
    "syns = (\".../450k/plp_selection/synonymous_rare/\"\n",
    "        \"all_chr_total_presumable_plps_HFE_final_sorted.txt\"\n",
    ")\n",
    "syns = pd.read_csv(syns, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "        syns.sample(n=plps.shape[0]).to_csv(f\".../450k/plp_selection/synonymous_rare/\"\n",
    "                f\"all_chr_total_presumable_plps_HFE_final_sorted_samples/sample_{i}.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbb_recessive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
