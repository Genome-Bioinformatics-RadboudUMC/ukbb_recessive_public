{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import tqdm \n",
    "\n",
    "from ukbb_recessive.regression.regressions import run_regressions, save_table_for_paper, get_formula, get_target_family"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5deeee7",
   "metadata": {},
   "source": [
    "# Load regressions datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d59ed4",
   "metadata": {},
   "source": [
    "First, we load datasets for the regression analysis saved on the previous step using script `0_create_dataset.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \".../ukbb_recessive/data/tables/sampling/synonymous\"\n",
    "datasets_path = '.../450k/datasets/sampling/synonymous'\n",
    "\n",
    "datasets_dict = {f\"Roulette_{idx}\":  pd.read_csv(f\"{datasets_path}/Roulette_sample_{idx}.csv\", sep='\\t') for idx in range(300)}\n",
    "\n",
    "# samples of interest: European & non-related without hom and comp_het\n",
    "european_non_rel_samples = (\n",
    "    \".../450k/samples/european_non_related_no_withdrawal_to_include_450k.no_hom_comp_het.txt\"\n",
    ")\n",
    "\n",
    "with open(european_non_rel_samples, 'r') as f:\n",
    "    european_non_rel_samples = [l.strip() for l in f.readlines()]\n",
    "\n",
    "print (f\"Number of european non-related samples without hom and comp_het: {len(european_non_rel_samples)}\\n\")\n",
    "\n",
    "for dataset_name, dataset in datasets_dict.items():\n",
    "    if dataset_name == 'Roulette_0':\n",
    "        print (f\"Number of samples in {dataset_name}: {datasets_dict[dataset_name].shape[0]}\")\n",
    "    \n",
    "    datasets_dict[dataset_name] = dataset[dataset['eid'].astype(str).isin(european_non_rel_samples)].copy()\n",
    "    \n",
    "    if dataset_name == 'Roulette_0':\n",
    "        print (f\"Number of samples in {dataset_name} after filtration: {datasets_dict[dataset_name].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1bb42",
   "metadata": {},
   "source": [
    "Here are all s_het-based genetic burdens, calculated based on different gene sets and variants (PLPs or singleton LOFs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6024d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datasets_dict[list(datasets_dict.keys())[0]].columns:\n",
    "    if col[:5] == 's_het':\n",
    "        print (col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93250eea",
   "metadata": {},
   "source": [
    "# Define analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e8866",
   "metadata": {},
   "source": [
    "We define all phenotypes (targets), that we would like to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = ['childlessness', 'years_of_edu', 'diagnosis_total_ICD10_cnt_log',\n",
    "              'ICD_infertility', 'fluid_intelligence_score', 'is_blond']\n",
    "\n",
    "phenotype_family = ['binomial', 'gaussian', 'gaussian', \n",
    "                    'binomial', 'gaussian', 'binomial']\n",
    "\n",
    "# we looked into phenotypes of interest\n",
    "phenotype_regressions = {\n",
    "    's_hets': ['s_het_recessive_all'],\n",
    "    'targets': phenotypes,\n",
    "    'families': phenotype_family,\n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 10,\n",
    "    'filter_dataset': lambda dataset: dataset\n",
    "}\n",
    "\n",
    "# we looked into ID vs rest\n",
    "id_vs_rest_phenotype_regressions = {\n",
    "    's_hets': ['s_het_recessive_AR_without_ID', 's_het_recessive_ID_total'],\n",
    "    'targets': phenotypes,\n",
    "    'families': phenotype_family,\n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 14,\n",
    "    'filter_dataset': lambda dataset: dataset\n",
    "}\n",
    "\n",
    "analyses = {\n",
    "    # 'synonymous_on_phenotype': phenotype_regressions,\n",
    "    'synonymous_id_vs_rest': id_vs_rest_phenotype_regressions,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e3b96c2",
   "metadata": {},
   "source": [
    "## All samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c91aad",
   "metadata": {},
   "source": [
    "We define all combinations of s-het burdens that we would like to check for the association with phenotypes and run the regressions for all samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda52737",
   "metadata": {},
   "outputs": [],
   "source": [
    "for analysis, analysis_cfg in analyses.items():\n",
    "\n",
    "    all_results = defaultdict(list)\n",
    "\n",
    "    print (f\"Running {analysis} analysis\\n\")\n",
    "\n",
    "    # read analysis config\n",
    "    s_hets = analysis_cfg['s_hets']\n",
    "    targets = analysis_cfg['targets']\n",
    "    families = analysis_cfg['families']\n",
    "    genders = analysis_cfg['genders']   \n",
    "    filter_dataset_func = analysis_cfg['filter_dataset']\n",
    "    n_tests_correction = analysis_cfg['n_tests_correction']\n",
    "     \n",
    "    \n",
    "    # iterate over different s-het datasets\n",
    "    for dataset_key in datasets_dict:\n",
    "        print (\"\\tProcessing\", dataset_key, flush=True)\n",
    "\n",
    "        # iterate over different s-het burdens\n",
    "        for s_het in s_hets:\n",
    "\n",
    "            if not (isinstance(s_het, list) or isinstance(s_het, tuple)) :\n",
    "                s_het = [s_het]\n",
    "\n",
    "            analysis_tag = f'{analysis} regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "            base_dataset_key, idx = tuple(dataset_key.split('_'))\n",
    "\n",
    "            print (f\"\\t\\tRun {analysis_tag}\")\n",
    "\n",
    "            dataset = filter_dataset_func(datasets_dict[dataset_key]).copy()\n",
    "            print (f\"\\t\\t\\tDataset size after filtration: {dataset.shape}\")\n",
    "            \n",
    "            if int(idx) >= 137:\n",
    "                dataset = dataset.rename(columns={'s_het_synonymous_all': 's_het_recessive_all', \n",
    "                                                  's_het_synonymous_AR_without_ID': 's_het_recessive_AR_without_ID', \n",
    "                                                  's_het_synonymous_ID-total': 's_het_recessive_ID_total'})\n",
    "            else:\n",
    "                dataset = dataset.rename(columns={'s_het_recessive_ID-total': 's_het_recessive_ID_total'})\n",
    "\n",
    "            regression_result = run_regressions(dataset=dataset, \n",
    "                                                targets=targets, \n",
    "                                                families=families, \n",
    "                                                analysis_tag=analysis_tag, \n",
    "                                                genders=genders, \n",
    "                                                s_het_list=s_het, \n",
    "                                                tab_offset='\\t\\t\\t', \n",
    "                                                n_tests_correction=n_tests_correction)\n",
    "            \n",
    "            all_results[dataset_key].append(regression_result)\n",
    "\n",
    "            print()\n",
    "\n",
    "    all_results = {dataset_key: pd.concat(all_results[dataset_key]) for dataset_key in all_results}\n",
    "    flatten_results = pd.concat(all_results.values(), axis=0)\n",
    "\n",
    "    save_table_for_paper(all_results=dict({base_dataset_key: flatten_results}),\n",
    "                        path=f\"{output_path}/table_{analysis}_analysis.xlsx\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah $output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae848b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "variant_prio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
