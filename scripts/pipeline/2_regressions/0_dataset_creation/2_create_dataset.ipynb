{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "\n",
    "from ukbb_recessive.data_collection.dataset import RegressionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_save_path = '.../450k/datasets'\n",
    "\n",
    "#_____________________________________________________________________________________________________________________________\n",
    "s_het_paths = {\n",
    "    'Weghorn-drift': \".../450k/selection_weghorn/weghorn_drift_gencode-v34.txt\",\n",
    "    'Cassa': \".../450k/selection_cassa/cassa_supp_table_1_gencode-v34.txt\",\n",
    "    'PLI': \".../450k/selection_pli/gnomad.v2.1.1.PLI_gencode-v34.txt\", \n",
    "    \"Roulette\": \".../450k/selection_roulette/s_het_roulette_gencode-v34.csv\",\n",
    "    'GeneBayes': \".../450k/selection_genebayes/s_het_genebayes_gencode-v34.csv\"\n",
    "}\n",
    "\n",
    "#_____________________________________________________________________________________________________________________________\n",
    "# phenotypic paths\n",
    "age_children_path = \".../450k/phenotypes/age_children_data_participant.tsv\" \n",
    "pca_path = \".../450k/phenotypes/PC_participant.tsv\"\n",
    "other_features_path = (\n",
    "    \".../450k/phenotypes/phenotypes_of_interest_participant.tsv\"\n",
    ")\n",
    "\n",
    "#_____________________________________________________________________________________________________________________________\n",
    "# samples of interest: European & non-related\n",
    "european_non_rel_samples = (\n",
    "    \".../450k/samples/european_non_related_no_withdrawal_to_include_450k.txt\"\n",
    ")\n",
    "\n",
    "#_____________________________________________________________________________________________________________________________\n",
    "# plps paths\n",
    "variants_paths_cfg = {\n",
    "    'recessive' : {\n",
    "        'cohort_files': glob.glob(\".../450k/RAP_output_per_chr/filtered_plps/basic/new_gene_names/new_freq/new_relatedness/chr*\"), \n",
    "        'all_variants_file': \".../450k/plp_selection/basic/new_gene_names/new_freq/new_relatedness/all_chr_total_presumable_plps_HFE_final_sorted.txt\"\n",
    "    },\n",
    "    'lof': {\n",
    "        'cohort_files': glob.glob(f\".../data_450k/sample_lofs/*.normed.csv\"),\n",
    "        'all_variants_file': \".../data_450k/annotations/all_singetones_annotated.csv\"\n",
    "    },\n",
    "}\n",
    "#_____________________________________________________________________________________________________________________________\n",
    "# gene info\n",
    "gencode = \".../genCode/GRCh38/v34/gencode.v34.GRCh38.txt\"\n",
    "\n",
    "\n",
    "#gene panel\n",
    "gene_panel = pd.read_csv(\".../450k/regions/gene-panel-gencode-v34.txt\", header=None)\n",
    "gene_panel.columns = ['Gene name', 'Gene panel']\n",
    "\n",
    "gene_panel_AR_without_id = gene_panel[gene_panel['Gene panel'] != 'ID-total'].copy()\n",
    "gene_panel_AR_without_id['Gene panel'] = 'AR_without_ID'\n",
    "\n",
    "gene_panel['Gene panel'] = gene_panel['Gene panel'].apply(lambda x: x.replace('-', '_').replace('+', '_'))\n",
    "\n",
    "gene_panel = pd.concat([gene_panel, gene_panel_AR_without_id])\n",
    "\n",
    "gene_panel.tail(3)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect phenotypic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(european_non_rel_samples, 'r') as f:\n",
    "    european_non_rel_samples = [l.strip() for l in f.readlines()]\n",
    "\n",
    "print (f\"Number of european non-related samples: {len(european_non_rel_samples)}\")\n",
    "\n",
    "features = RegressionDataset(\n",
    "    age_children_path = age_children_path, \n",
    "    pca_path = pca_path, \n",
    "    other_features_path = other_features_path,\n",
    "    samples_list = european_non_rel_samples, \n",
    ").collect_phenotypic_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Mistakes children:\", sum((~features['number_of_children_fathered'].isnull()) & (~features['number_of_live_births'].isnull())))\n",
    "print (\"Missing children:\", sum((features['number_of_children_fathered'].isnull()) & (features['number_of_live_births'].isnull())))\n",
    "print (\"Missing children:\", sum(features['number_of_children_MF'].isnull()))\n",
    "print (\"Childlessness:\", int(features['childlessness'].sum()))\n",
    "print (\"Childlessness missing:\", sum(features['childlessness'].isnull()))\n",
    "\n",
    "\n",
    "features[['number_of_children_fathered', 'number_of_live_births', 'number_of_children_MF']].hist(bins=8, figsize=(20, 3), layout=(1, 3))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Total number of individuals:\", features.shape[0])\n",
    "print (\"Number of individuals with university degree:\", int(features['uni_1_0_including_none'].sum()))\n",
    "print (\"Number of individuals with higher educational degree:\", int(features['higher_education_including_none'].sum()))\n",
    "\n",
    "qualifications = features[['eid', 'qualifications']].copy()\n",
    "qualifications['qualifications'] = qualifications['qualifications'].apply(lambda x: x.split('|'))\n",
    "qualifications = qualifications.explode('qualifications')\n",
    "qualifications.drop_duplicates().groupby('qualifications').count().plot.barh()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Number of individuals with partner:\", int(features['living_with_a_partner'].sum()))\n",
    "print()\n",
    "print (\"Number of individuals with mental health ICD diagnosis:\", int(features['ICD_mental_health_yes_no'].sum()))\n",
    "print (\"Number of individuals with mental health questionnarie:\", int(features['mental_health_Q'].sum()))\n",
    "print()\n",
    "print (\"Number of individuals with email:\", int(features['email'].sum()))\n",
    "print()\n",
    "print (\"Number of ever had sex:\", int(features['ever_had_sex'].sum()))\n",
    "print (\"Number of never had sex:\", int((1 - features['ever_had_sex']).sum()))\n",
    "print()\n",
    "print (\"Number has gp record sex:\", int(features['has_gp_record'].sum()))\n",
    "print()\n",
    "print (\"Number left-handed:\", int(features['is_left_handed'].sum()))\n",
    "print()\n",
    "print (\"Number blond:\", int(features['is_blond'].sum()))\n",
    "print()\n",
    "print (\"Number infertility:\", int(features['ICD_infertility'].sum()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect s-het info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare gene panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gene panels recessive\n",
    "recessive_panels_dict = gene_panel.groupby('Gene panel').agg({'Gene name': lambda x: list(x)}).to_dict()['Gene name']\n",
    "recessive_panels_dict['all'] = None\n",
    "\n",
    "ADAR_genes = pd.read_csv('.../450k/regions/ADAR_genes_gencode-v34.txt', header=None)[0].values.tolist()\n",
    "\n",
    "recessive_panels_dict['AD'] = ADAR_genes\n",
    "recessive_panels_dict['AR'] = list(set(gene_panel['Gene name'].unique().tolist()) - set(ADAR_genes))\n",
    "\n",
    "\n",
    "recessive_panels_dict['ID_without_AD'] = list(set(recessive_panels_dict['ID_total']) - set(ADAR_genes))\n",
    "\n",
    "\n",
    "# Create gene panels for lof\n",
    "all_genes = set(pd.read_csv(gencode, sep='\\t', low_memory=False)['name2'].drop_duplicates().values.tolist())\n",
    "AR_genes = set(gene_panel['Gene name'].drop_duplicates().values.tolist())\n",
    "\n",
    "\n",
    "ID_AR_genes = set(recessive_panels_dict['ID_total'])\n",
    "non_ID_AR_genes = AR_genes - ID_AR_genes\n",
    "\n",
    "non_AR_genes = all_genes - AR_genes\n",
    "lof_panels_dict = {'all': None, 'without_AR': non_AR_genes, 'AR': AR_genes}\n",
    "\n",
    "print (\"All genes number:\", len(all_genes))\n",
    "print (\"Non-AR genes number:\", len(non_AR_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_het_cfg = {\n",
    "    'lof': lof_panels_dict,\n",
    "    'recessive' : recessive_panels_dict\n",
    "}\n",
    "\n",
    "for dataset_type in s_het_cfg:\n",
    "    print (f\"Dataset = {dataset_type}\")\n",
    "    for panel, gene_list in s_het_cfg[dataset_type].items():\n",
    "\n",
    "        print (f\"\\tPanel={panel}, number of genes={len(gene_list) if gene_list is not None else 'NA' }\")\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect s_het data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "\n",
    "for s_het_key, s_het_path in s_het_paths.items():\n",
    "    print (f\"Collecting data for {s_het_key}\\n\")\n",
    "\n",
    "    for dataset_type in s_het_cfg:\n",
    "        print (f\"Dataset = {dataset_type}\")\n",
    "\n",
    "        for panel, gene_list in s_het_cfg[dataset_type].items():\n",
    "\n",
    "            print (f\"\\tPanel={panel}, number of genes={len(gene_list) if gene_list is not None else 'NA' }\")\n",
    "            print (\"_____________________\")\n",
    "            s_het_features = RegressionDataset(\n",
    "                het_occurrence_threshold=20., \n",
    "                all_plps_file=variants_paths_cfg[dataset_type]['all_variants_file'], \n",
    "                s_het_file=s_het_path,\n",
    "                cohort_plps_files=variants_paths_cfg[dataset_type]['cohort_files'], \n",
    "                genes_list=gene_list,\n",
    "                dataset=dataset_type\n",
    "            ).collect_variant_features()\n",
    "            \n",
    "            # rename columns\n",
    "            for col in s_het_features.columns.tolist():\n",
    "                if col != 'eid':\n",
    "                    s_het_features = s_het_features.rename(columns={col: f\"{col}_{dataset_type}_{panel}\"})\n",
    "\n",
    "            if s_het_key not in result:\n",
    "                result[s_het_key] = s_het_features\n",
    "            else:\n",
    "                result[s_het_key] = result[s_het_key].merge(s_het_features, on=\"eid\", how='outer')\n",
    "            print (\"_____________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shapes\n",
    "for s_het_key in s_het_paths:\n",
    "    print (f\"Shape for variants features of {s_het_key}:\", result[s_het_key].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and fill-in NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # fill NA for s_het with PLP but no information about s_het\n",
    "fill_na_shet = True\n",
    "\n",
    "for s_het_key in s_het_paths:\n",
    "    print (f\"Merging data for {s_het_key}\")\n",
    "\n",
    "    result[s_het_key] = features.merge(result[s_het_key], on='eid', how='left')\n",
    "\n",
    "    for dataset_type in s_het_cfg:\n",
    "        print (f\"\\tDataset = {dataset_type}\")\n",
    "\n",
    "        for panel, gene_list in s_het_cfg[dataset_type].items():\n",
    "            \n",
    "            columns = [f\"{col}_{dataset_type}_{panel}\" for col in ['s_het', 'mutations_cnt', 'has_mutation']]\n",
    "\n",
    "            # fills NAs with 0s\n",
    "            result[s_het_key][columns] = result[s_het_key][columns].fillna(0.)\n",
    "\n",
    "            # fill NAs for s_het of recessive PLP carriers with no s_het information\n",
    "            if fill_na_shet:\n",
    "                result[s_het_key].loc[(result[s_het_key][f'mutations_cnt_{dataset_type}_{panel}'] > 0) & \n",
    "                                      (result[s_het_key][f's_het_{dataset_type}_{panel}'] == 0),  f's_het_{dataset_type}_{panel}'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shapes\n",
    "for s_het_key in s_het_paths:\n",
    "    print (f\"Shape for all features of {s_het_key}:\", result[s_het_key].shape)\n",
    "\n",
    "# Shape for all features of Weghorn-drift: (376872, 231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_het_key in s_het_paths:\n",
    "    print (f\"Saving {s_het_key}\", flush=True)\n",
    "    result[s_het_key].to_csv(f'{datasets_save_path}/{s_het_key}.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lah .../450k/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbb_recessive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
