{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the pipeline for the LoF variants extraction from UKBB 450k data. \n",
    "It is an approximation of the method explained in the [paper](https://www.nature.com/articles/s41586-022-04549-9). \n",
    "\n",
    "This notebook should be placed in UKBB Research Analysis Platform. \n",
    "\n",
    "The cell that contains `chromosome` variable should be tagged  as explained [here](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#designate-parameters-for-a-cell). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-&amp;-preparation\" data-toc-modified-id=\"Import-&amp;-preparation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import &amp; preparation</a></span></li><li><span><a href=\"#Load-and-filter-variants-by-bed\" data-toc-modified-id=\"Load-and-filter-variants-by-bed-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load and filter variants by bed</a></span></li><li><span><a href=\"#VEP\" data-toc-modified-id=\"VEP-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>VEP</a></span></li><li><span><a href=\"#Filter-missing-genotypes\" data-toc-modified-id=\"Filter-missing-genotypes-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Filter missing genotypes</a></span></li><li><span><a href=\"#How-to-run-it\" data-toc-modified-id=\"How-to-run-it-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>How to run it</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to running the notebook, the following data should be uploaded to the RAP:\n",
    "1. The GRCh38 coordinates of the targeted regions `xgen_plus_spikein.GRCh38.bed` from https://biobank.ndph.ox.ac.uk/ukb/refer.cgi?id=3803 .\n",
    "\n",
    "2. The GRCh38 coordinates of the genes with s-het>=0.15 `high_s_het_gene_list_10bp.bed` from the previous step.\n",
    "\n",
    "3. List of unrelated samples `unrelated_samples.txt`. \n",
    "\n",
    "In this section we also download `pvcf_blocks.txt` as the data for each chromosome is splitted across several files, marked by `block_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.947476,
     "end_time": "2022-10-17T15:35:16.395297",
     "exception": false,
     "start_time": "2022-10-17T15:35:10.447821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import hail as hl\n",
    "import pandas as pd\n",
    "\n",
    "# initialize Spark and Hail contexts\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "hl.init(sc=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell should be tagged as explained [here](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#designate-parameters-for-a-cell).\n",
    "\n",
    "It will be used as a command line argument for a papermill tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged parameters (will act as a command line argument)\n",
    "chromosome = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.382021,
     "end_time": "2022-10-17T15:35:18.786353",
     "exception": false,
     "start_time": "2022-10-17T15:35:16.404332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load bed for target sequencing region\n",
    "target_bed_path = 'file:///.../xgen_plus_spikein.GRCh38.bed' # should be specified\n",
    "\n",
    "bed_target = hl.import_bed(target_bed_path, reference_genome='GRCh38')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load file, that contains bed regions of the genes with `s_het > 0.15`. We will use it for the filtration. This file was generated on the previous step `1_create_gene_list_turbo.ipynb` and copied to `Uploaded data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.760454,
     "end_time": "2022-10-17T15:35:19.554964",
     "exception": false,
     "start_time": "2022-10-17T15:35:18.794510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load bed for genes with s_het>0.15\n",
    "contig_recoding = {str(i): 'chr' + str(i) for i in range(1, 23)}\n",
    "contig_recoding.update({'X': 'chrX', 'Y': 'chrY', 'MT': 'chrM'})\n",
    "\n",
    "genes_bed_path = 'file:///.../high_s_het_gene_list_10bp.bed'  # should be specified\n",
    "\n",
    "bed_genes = hl.import_bed(genes_bed_path, reference_genome='GRCh38', contig_recoding=contig_recoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the list of samples, created by the main pipeline, that contains **unrelated** participants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.053479,
     "end_time": "2022-10-17T15:35:20.616904",
     "exception": false,
     "start_time": "2022-10-17T15:35:19.563425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load samples that should be used in analysis and doesnt contain related samples\n",
    "\n",
    "unrelated_samples_path = ... # should be specified\n",
    "\n",
    "with open(unrelated_samples_path, 'r') as f:\n",
    "    samples_list = f.readlines()\n",
    "    \n",
    "samples_list = [sample_id.strip() for sample_id in samples_list]\n",
    "n_samples = len(samples_list)\n",
    "\n",
    "print (n_samples)\n",
    "\n",
    "samples_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pVCF files are stored in blocks, so that every chromosome is divided into several files. Here we load information about the blocks created for every chromosome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pvcf blocks file\n",
    "pvcf_blocks = pd.read_csv(\"https://biobank.ctsu.ox.ac.uk/crystal/ukb/auxdata/pvcf_blocks.txt\", \n",
    "                          sep='\\t', header=None)\n",
    "pvcf_blocks.columns = ['row_id', 'chrom', 'block_id', 'start', 'end']\n",
    "\n",
    "chromosome_pvcf_blocks = pvcf_blocks[pvcf_blocks['chrom'].astype(int) == int(chromosome)]['block_id'].tolist()\n",
    "\n",
    "print (len(chromosome_pvcf_blocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008619,
     "end_time": "2022-10-17T15:35:20.634404",
     "exception": false,
     "start_time": "2022-10-17T15:35:20.625785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and filter variants by bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we:  \n",
    "\n",
    "1. Load all gvcfs associated with a `chromosome`.\n",
    "\n",
    "2. Leave only target regions and genes of interest (`s_het >= 0.15`) as described [here](https://hail.is/docs/0.2/guides/genetics.html#from-a-ucsc-bed-file).\n",
    "\n",
    "3. Concatenate all gvcfs into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014531,
     "end_time": "2022-10-17T15:35:20.657561",
     "exception": false,
     "start_time": "2022-10-17T15:35:20.643030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# we define a loading function\n",
    "def load_filter_gvcf(gvcf_path):\n",
    "    \"\"\"\n",
    "        Reads gvcf stored in `gvcf_path` and \n",
    "        filters target regions and genes of interest\n",
    "        defined in `bed_genes` and `bed_target`.\n",
    "    \"\"\"\n",
    "    print (f\"load {gvcf_path}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    gvcf = hl.methods.import_vcf(gvcf_path, \n",
    "                                 force_bgz=True, \n",
    "                                 reference_genome='GRCh38', \n",
    "                                 array_elements_required=False,\n",
    "                                 block_size=32)\n",
    "    \n",
    "    # this is described here https://hail.is/docs/0.2/guides/genetics.html#from-a-ucsc-bed-file \n",
    "    gvcf = gvcf.filter_rows(hl.is_defined(bed_genes[gvcf.locus]))\n",
    "    gvcf = gvcf.filter_rows(hl.is_defined(bed_target[gvcf.locus]))\n",
    "    \n",
    "    return gvcf\n",
    "\n",
    "# function, that loads several gVCFs\n",
    "def load_concatenate_gvcfs(gvcf_paths):\n",
    "    \"\"\"\n",
    "        Reads all gvcfs defined in `gvcf_paths` list\n",
    "    \"\"\"\n",
    "    gvcfs = [load_filter_gvcf(gvcf_path) for gvcf_path in gvcf_paths]\n",
    "    \n",
    "    return gvcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 318.132078,
     "end_time": "2022-10-17T15:40:38.799759",
     "exception": false,
     "start_time": "2022-10-17T15:35:20.667681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate all gvcf paths for a given chromosome\n",
    "gvcf_paths = [\n",
    "    f'file:///.../'\n",
    "    f'Population level exome OQFE variants, pVCF format - final release/ukbXXXXX_c{chromosome}_b{idx}_v1.vcf.gz' for idx in chromosome_pvcf_blocks\n",
    "] # should be specified\n",
    "\n",
    "# load all gvcfs for a given chromosome\n",
    "vcf = load_concatenate_gvcfs(gvcf_paths)\n",
    "\n",
    "# concatenate all vcfs together, may trigger a shuffle if partitions overlap.\n",
    "full_vcf = hl.MatrixTable.union_rows(*vcf, _check_cols=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013336,
     "end_time": "2022-10-17T15:40:38.865201",
     "exception": false,
     "start_time": "2022-10-17T15:40:38.851865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we : \n",
    "1. Annotate variants with VEP\n",
    "    a. Here we use `json.vep` configuration file, the same file can be found next to the script file.\n",
    "\n",
    "    b. `transcript_consequences` field will contain all consequences mapped to the variants in the location. \n",
    "\n",
    "2. Leave only variants, that are high quality LoF (based on lottee) in any canonical transcript: \n",
    "\n",
    "    a. Iterate over all consequences in `transcript_consequences`, select canonical transcripts and parse consequence term. \n",
    "\n",
    "    b. For LoF consequence check if it is high quality or low quality as annotated by Loftee. \n",
    "\n",
    "    c. Leave only locuses with LoF high-quality variants as annotated in canonical transcript. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.020626,
     "end_time": "2022-10-17T15:40:38.899147",
     "exception": false,
     "start_time": "2022-10-17T15:40:38.878521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function, that defines LoF variant\n",
    "def is_lof(consequence_terms):\n",
    "    is_lof = (\n",
    "        consequence_terms.contains(\"splice_acceptor_variant\") | \n",
    "        consequence_terms.contains(\"splice_donor_variant\") | \n",
    "        consequence_terms.contains(\"stop_gained\") | \n",
    "        consequence_terms.contains(\"frameshift_variant\")\n",
    "    )\n",
    "    \n",
    "    return is_lof\n",
    "\n",
    "\n",
    "# function, that parses synonimous, LoF, missense protein consequences in canonical transcript\n",
    "# and otherwise returns missing value\n",
    "def process_transcript_consequences(transcript_consequence):    \n",
    "    return hl.if_else(transcript_consequence.canonical == 1, \n",
    "                      hl.case()\n",
    "                        .when(transcript_consequence.consequence_terms.contains(\"synonymous_variant\"),\n",
    "                              hl.struct(allele_num=transcript_consequence.allele_num, consq='synonymous'))\n",
    "                        .when(is_lof(transcript_consequence.consequence_terms) & (transcript_consequence.lof == 'HC'),\n",
    "                              hl.struct(allele_num=transcript_consequence.allele_num, consq='lof_hc'))\n",
    "                        .when(is_lof(transcript_consequence.consequence_terms) & (transcript_consequence.lof == 'LC'),\n",
    "                              hl.struct(allele_num=transcript_consequence.allele_num, consq='lof_lc'))\n",
    "                        .when(transcript_consequence.consequence_terms.contains(\"missense_variant\"),\n",
    "                              hl.struct(allele_num=transcript_consequence.allele_num, consq='missense'))\n",
    "                        .or_missing(), \n",
    "                      hl.missing('struct{allele_num: int32, consq: str}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1348.900886,
     "end_time": "2022-10-17T16:03:07.813367",
     "exception": false,
     "start_time": "2022-10-17T15:40:38.912481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annotate gVCF with vep\n",
    "annotated_vcf = hl.vep(full_vcf, \"file:///.../json.vep\")\n",
    "\n",
    "# parse consequences \n",
    "annotated_vcf = annotated_vcf.annotate_rows(vep_canonical_consequences=hl.map(process_transcript_consequences, \n",
    "                                                                              annotated_vcf.vep.transcript_consequences))\n",
    "\n",
    "# leave only variants that have high quality LoF in at least one canonical transcript\n",
    "lof_vcf = annotated_vcf.filter_rows(hl.any(hl.map(lambda x: x.consq == 'lof_hc', \n",
    "                                                  annotated_vcf.vep_canonical_consequences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026553,
     "end_time": "2022-10-17T16:03:07.866762",
     "exception": false,
     "start_time": "2022-10-17T16:03:07.840209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Filter missing genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we filter out variants based on the quality as it wass described in the [paper](https://www.nature.com/articles/s41586-022-04549-9):\n",
    "\n",
    "1. Leave only unrelated samples\n",
    "\n",
    "2. Calculate p-value for twwi-sided binomial test (number of supporting alleles, total coverage, p=0.5) for only heterozygous variants \n",
    "\n",
    "3. Leave only samples with `DP >=7`, `GQ >=20` and `p-value > 0.001`(if applicable)\n",
    "\n",
    "4. Add information about number of non-empty genotypes per row, and filter locuses with more that 50& missing genotypes. \n",
    "\n",
    "5. Save resulting vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.583665,
     "end_time": "2022-10-17T16:03:10.476995",
     "exception": false,
     "start_time": "2022-10-17T16:03:07.893330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# leave only unrelated samples\n",
    "lof_vcf = lof_vcf.filter_cols(hl.array(samples_list).contains(lof_vcf.s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037574,
     "end_time": "2022-10-17T16:03:10.541520",
     "exception": false,
     "start_time": "2022-10-17T16:03:10.503946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate binomial test p-value for heterozygous variant\n",
    "lof_vcf = lof_vcf.annotate_entries(pval=hl.if_else(lof_vcf.GT.is_het(),\n",
    "                                                   hl.binom_test(lof_vcf.AD[lof_vcf.GT[1]], lof_vcf.DP, 0.5, 'two-sided'), \n",
    "                                                   1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.035517,
     "end_time": "2022-10-17T16:03:10.603555",
     "exception": false,
     "start_time": "2022-10-17T16:03:10.568038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace genotypes with low reliability to missing\n",
    "\n",
    "lof_vcf = lof_vcf.filter_entries((lof_vcf.DP >= 7) & (lof_vcf.GQ >= 20) & (lof_vcf.pval > 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.040211,
     "end_time": "2022-10-17T16:03:10.670452",
     "exception": false,
     "start_time": "2022-10-17T16:03:10.630241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter variants with more than 50% missing genotypes\n",
    "\n",
    "lof_vcf = lof_vcf.annotate_rows(non_empty=hl.agg.count())\n",
    "lof_vcf = lof_vcf.filter_rows(lof_vcf.non_empty >= n_samples/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as vcf\n",
    "hl.export_vcf(lof_vcf, f'file:///.../chr{chromosome}_lof.vcf.bgz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanup log files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /.../hail*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run it for a specific chromosome the following things should be done:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy `2_data_collection_paper_rap` to UKBB RAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For every chromosome submit the following command:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_cmd=\"papermill 2_data_collection_paper_rap.ipynb Data_collection_paper_chrNN_output.ipynb -p chromosome NN\"`\n",
    "\n",
    "`dx run dxjupyterlab_spark_cluster --instance-type=mem2_ssd1_v2_x16 --instance-count=5 --priority=low --name=\"Run analysis chrNN\" -icmd=\"$my_cmd\" -iduration=480 -iin=\"../2_data_collection_paper_rap.ipynb\" -ifeature=\"HAIL-0.2.78-VEP-1.0.3\"`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands should be submitted from a local machine with installed CLI for DNAnexus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "311.64404296875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
