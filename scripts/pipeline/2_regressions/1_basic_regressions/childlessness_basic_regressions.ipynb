{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from ukbb_recessive.regression.regressions import run_regressions, save_table_for_paper, get_formula, get_target_family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regressions datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load datasets for the regression analysis saved on the previous step using script `0_create_dataset.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../../../../data/tables\"\n",
    "datasets_path = '.../450k/datasets'\n",
    "\n",
    "datasets_dict = {\n",
    "    'Cassa': pd.read_csv(f\"{datasets_path}/Cassa.csv\", sep='\\t'),\n",
    "    'pLI': pd.read_csv(f\"{datasets_path}/PLI.csv\", sep='\\t'),\n",
    "    'Weghorn': pd.read_csv(f\"{datasets_path}/Weghorn-drift.csv\", sep='\\t'),\n",
    "    'Roulette': pd.read_csv(f\"{datasets_path}/Roulette.csv\", sep='\\t'),\n",
    "}\n",
    "\n",
    "# samples of interest: European & non-related without hom and comp_het\n",
    "european_non_rel_samples = (\n",
    "    \".../450k/samples/european_non_related_no_withdrawal_to_include_450k.no_hom_comp_het.txt\"\n",
    ")\n",
    "\n",
    "with open(european_non_rel_samples, 'r') as f:\n",
    "    european_non_rel_samples = [l.strip() for l in f.readlines()]\n",
    "\n",
    "print (f\"Number of european non-related samples without hom and comp_het: {len(european_non_rel_samples)}\\n\")\n",
    "\n",
    "for dataset_name, dataset in datasets_dict.items():\n",
    "    print (f\"Number of samples in {dataset_name}: {datasets_dict[dataset_name].shape[0]}\")\n",
    "    datasets_dict[dataset_name] = dataset[dataset['eid'].astype(str).isin(european_non_rel_samples)].copy()\n",
    "    print (f\"Number of samples in {dataset_name}: {datasets_dict[dataset_name].shape[0]}\")\n",
    "\n",
    "    datasets_dict[dataset_name]['diagnosis_secondary_ICD10_cnt_log'] = np.log(datasets_dict[dataset_name]['diagnosis_secondary_ICD10_cnt'])\n",
    "    datasets_dict[dataset_name]['diagnosis_main_ICD10_cnt_log'] = np.log(datasets_dict[dataset_name]['diagnosis_main_ICD10_cnt'])\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all s_het-based genetic burdens, calculated based on different gene sets and variants (PLPs or singleton LOFs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datasets_dict[list(datasets_dict.keys())[0]].columns:\n",
    "    if col[:5] == 's_het':\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we tried to look into the effect of being a carrier of PLP in recessive gene without taking into account the selection constraint.\n",
    "preliminary_regresions = {\n",
    "    's_hets': ['has_mutation_recessive_all', 'mutations_cnt_recessive_all', 'has_mutation_lof_without_AR'],\n",
    "    'targets': ['childlessness'],\n",
    "    'families': ['binomial'], \n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 10,\n",
    "    'filter_dataset': lambda dataset: dataset\n",
    "}\n",
    "\n",
    "#we define all combinations of s-het burdens that we would like to check for the association with phenotypes and run the regressions for all samples:\n",
    "s_het_regressions = {\n",
    "    's_hets': ['s_het_recessive_all', 's_het_lof_without_AR', \n",
    "               ['s_het_recessive_all', 's_het_lof_without_AR']],\n",
    "    'targets': ['childlessness', 'is_blond'],\n",
    "    'families': ['binomial', 'binomial'], \n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 10,\n",
    "    'filter_dataset': lambda dataset: dataset\n",
    "}\n",
    "\n",
    "#to ensure, that our resuls are not confounded by the LoF carriers in other genes, we exclude all those carriers and repeat the analysis for PLPs in all recessive genes:\n",
    "exclude_lof_carriers = {\n",
    "    's_hets': ['s_het_recessive_all'],\n",
    "    'targets': ['childlessness', 'is_blond'],\n",
    "    'families': ['binomial', 'binomial'], \n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 10,\n",
    "    'filter_dataset': lambda dataset: dataset[dataset['has_mutation_lof_without_AR'].fillna(0) != 1]\n",
    "}\n",
    "\n",
    "analyses = {\n",
    "    'preliminary': preliminary_regresions,\n",
    "    'selection': s_het_regressions, \n",
    "    'exlude_lof_carriers': exclude_lof_carriers\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = defaultdict(list)\n",
    "\n",
    "for analysis, analysis_cfg in analyses.items():\n",
    "\n",
    "    print (f\"Running {analysis} analysis\\n\")\n",
    "\n",
    "    # read analysis config\n",
    "    s_hets = analysis_cfg['s_hets']\n",
    "    targets = analysis_cfg['targets']\n",
    "    families = analysis_cfg['families']\n",
    "    genders = analysis_cfg['genders']   \n",
    "    filter_dataset_func = analysis_cfg['filter_dataset']\n",
    "    n_tests_correction = analysis_cfg['n_tests_correction']\n",
    "     \n",
    "    \n",
    "    # iterate over different s-het datasets\n",
    "    for dataset_key in datasets_dict:\n",
    "        print (\"\\tProcessing\", dataset_key, flush=True)\n",
    "\n",
    "        # iterate over different s-het burdens\n",
    "        for s_het in s_hets:\n",
    "            if not isinstance(s_het, list):\n",
    "                s_het = [s_het]\n",
    "\n",
    "            analysis_tag = f'{analysis} regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "            print (f\"\\t\\tRun {analysis_tag}\")\n",
    "\n",
    "            dataset = filter_dataset_func(datasets_dict[dataset_key]).copy()\n",
    "            print (f\"\\t\\t\\tDataset size aftexr filtration: {dataset.shape}\")\n",
    "\n",
    "            regression_result = run_regressions(dataset=dataset, \n",
    "                                                targets=targets, \n",
    "                                                families=families, \n",
    "                                                analysis_tag=analysis_tag, \n",
    "                                                genders=genders, \n",
    "                                                s_het_list=s_het, \n",
    "                                                tab_offset='\\t\\t\\t', \n",
    "                                                n_tests_correction=n_tests_correction)\n",
    "            \n",
    "            all_results[dataset_key].append(regression_result)\n",
    "\n",
    "            print()\n",
    "    print()\n",
    "\n",
    "all_results = {dataset_key: pd.concat(all_results[dataset_key]) for dataset_key in all_results}\n",
    "\n",
    "save_table_for_paper(all_results, f\"{output_path}/table_selection_analysis.xlsx\", keep_effects=preliminary_regresions['s_hets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lah ../../../../data/tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraints test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = s_het_regressions['targets']\n",
    "families = s_het_regressions['families']\n",
    "\n",
    "target_results = defaultdict(dict)\n",
    "\n",
    "for target, family in zip(targets, families):\n",
    "    print (\"Processing\", target, flush=True)\n",
    "\n",
    "    formula = get_formula(target=target, s_het_list=['s_het_recessive_all', 's_het_lof_without_AR'])\n",
    "\n",
    "    # run regressions\n",
    "    model = smf.glm(formula = formula, data=datasets_dict['Roulette'].copy(), family=get_target_family(family))\n",
    "    fitted_model = model.fit()\n",
    "    \n",
    "    target_results[target] = fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(target)\n",
    "\n",
    "    print(target_results[target].t_test(\n",
    "        's_het_recessive_all = s_het_lof_without_AR', use_t=True))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(target)\n",
    "\n",
    "    print(target_results[target].wald_test(\n",
    "        's_het_recessive_all = s_het_lof_without_AR'), scalar=True)\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbb_recessive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
