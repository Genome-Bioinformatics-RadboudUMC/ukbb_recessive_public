{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5e6aee",
   "metadata": {},
   "source": [
    "This script converts data to the format that is expected by further steps. \n",
    "\n",
    "It is also normalizes variants (converts them to the minimal form) and genotypes (converts them from multialleic form (e.g. 2/3) to biallelic form - 0/1, 1/0, 1/1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd470338",
   "metadata": {},
   "source": [
    "# Imorts and functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2c5b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import numpy as np\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc2369c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# minimal representation of the variant\n",
    "\n",
    "def get_minimal_representation(pos, ref, alt): \n",
    "    \"\"\"\n",
    "    Creates minimal representation for alleles. \n",
    "    \n",
    "    Taken from here:\n",
    "        http://www.cureffi.org/2014/04/24/converting-genetic-variants-to-their-minimal-representation/\n",
    "    \"\"\"\n",
    "    # If it's a simple SNV, don't remap anything\n",
    "    if len(ref) == 1 and len(alt) == 1: \n",
    "        return pos, ref, alt\n",
    "    else:\n",
    "        # strip off identical suffixes (from the end)\n",
    "        while(alt[-1] == ref[-1] and min(len(alt),len(ref)) > 1):\n",
    "            alt = alt[:-1]\n",
    "            ref = ref[:-1]\n",
    "            \n",
    "        # strip off identical prefixes (from the start) and increment position\n",
    "        while(alt[0] == ref[0] and min(len(alt),len(ref)) > 1):\n",
    "            alt = alt[1:]\n",
    "            ref = ref[1:]\n",
    "            pos += 1\n",
    "            \n",
    "        return pos, ref, alt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df40f19",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_new_genotype(old_genotype, allele):\n",
    "    \"\"\"\n",
    "        Converts genotype from Hail's multi-allelic vcf representation \n",
    "        to biallelic 0/1, 1/0, 1/1\n",
    "    \"\"\"\n",
    "    result_genotype = np.array([0, 0])\n",
    "    result_genotype[np.array(old_genotype) == allele] = 1\n",
    "    \n",
    "    return \"/\".join(map(str, result_genotype.tolist()))\n",
    "\n",
    "# alleles parsing (includes application of the minimal representation)\n",
    "def parse_alleles_from_hail(row):\n",
    "    \"\"\"\n",
    "        Splits multi-allelic variants (e.g. 1/2) into biallelic 1/0, 0/1, 1/1\n",
    "        Gets minimal representation of the variants\n",
    "    \"\"\"\n",
    "    \n",
    "    # cast types \n",
    "    row['locus.position'] = int(row['locus.position'])\n",
    "    alleles = eval(row['alleles'])\n",
    "    genotype = eval(row['GT.alleles'])\n",
    "    \n",
    "    result_rows = []\n",
    "        \n",
    "    for gt in set(genotype):\n",
    "        \n",
    "        if gt == 0:\n",
    "            continue\n",
    "        \n",
    "        result_row = row.copy()\n",
    "        \n",
    "        # parse alleles \n",
    "        result_row['ref'] = alleles[0]\n",
    "        result_row['alt'] = alleles[gt]\n",
    "        \n",
    "        # parse genotype\n",
    "        result_row['GT'] = get_new_genotype(genotype, gt)\n",
    "\n",
    "        # save old variant representation\n",
    "        result_row['raw pos'], result_row['raw ref'], result_row['raw alt'] = (\n",
    "            result_row['locus.position'], result_row['ref'], result_row['alt']\n",
    "        )\n",
    "\n",
    "        # get minimal representation\n",
    "        result_row['pos'], result_row['ref'], result_row['alt'] = get_minimal_representation(\n",
    "            result_row['locus.position'],\n",
    "            result_row['ref'], \n",
    "            result_row['alt']) \n",
    "        \n",
    "        result_row['chrom'] = result_row['locus.contig']\n",
    "        \n",
    "        # delete unnecessary info\n",
    "        del result_row['']\n",
    "        del result_row['locus.contig']\n",
    "        del result_row['locus.position']\n",
    "        del result_row['GT.phased']\n",
    "        \n",
    "        result_rows.append(result_row)\n",
    "        \n",
    "    return result_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68e205",
   "metadata": {},
   "source": [
    "This function iterates over all variants in an input file and does 2 things: \n",
    "1. Gets minimal representation of the variant\n",
    "\n",
    "2. Converts genotypes grom multi-allelic of gVCF form to bi-allelic form of VCF. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95481487",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# processing of a file\n",
    "def process_and_save_vcf(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "        Applies all transformation to every row of the input file \n",
    "        and saves the result as gzipped csv\n",
    "    \"\"\"\n",
    "    \n",
    "    if output_path is None:\n",
    "        output_path = input_path.replace('.csv.gz', '.norm.csv.gz')\n",
    "\n",
    "    with gzip.open(input_path, 'rt') as in_csvfile, gzip.open(output_path, 'wt') as out_csvfile:\n",
    "        \n",
    "        # define output csv file field names\n",
    "        fieldnames = ['chrom', 'pos', 'ref', 'alt', 'GT', 's', \n",
    "                      'raw pos', 'raw ref', 'raw alt', 'alleles', 'GT.alleles']\n",
    "        \n",
    "        # create writer\n",
    "        processed_data = csv.DictWriter(out_csvfile, fieldnames=fieldnames)\n",
    "        processed_data.writeheader()\n",
    "        \n",
    "        # create reader\n",
    "        data = csv.DictReader(in_csvfile)\n",
    "        parsed_data = []\n",
    "        \n",
    "        # process every line of the input file\n",
    "        for row in data:\n",
    "            for processed_row in parse_alleles_from_hail(row):\n",
    "                processed_data.writerow(processed_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1226b",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c511ed8",
   "metadata": {},
   "source": [
    "First, we collect all the file names for future processing, that contain variants derived from RAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e8ce21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.../450k_data/chr18',\n",
       " '.../450k_data/chr3',\n",
       " '.../450k_data/chr20',\n",
       " '.../450k_data/chr17',\n",
       " '.../450k_data/chr8',\n",
       " '.../450k_data/chr19',\n",
       " '.../450k_data/chr15',\n",
       " '.../450k_data/chr10',\n",
       " '.../450k_data/chr12',\n",
       " '.../450k_data/chr16',\n",
       " '.../450k_data/chr14',\n",
       " '.../450k_data/chr5',\n",
       " '.../450k_data/chr22',\n",
       " '.../450k_data/chr2',\n",
       " '.../450k_data/chr6',\n",
       " '.../450k_data/chr7',\n",
       " '.../450k_data/chr1',\n",
       " '.../450k_data/chr9',\n",
       " '.../450k_data/chr13',\n",
       " '.../450k_data/chr21',\n",
       " '.../450k_data/chr4',\n",
       " '.../450k_data/chr11']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromosomes = glob.glob(f\".../450k_data/chr*[0-9]\")\n",
    "\n",
    "chromosomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1a17f",
   "metadata": {},
   "source": [
    "Then we process all input files by using function defined earlier. We do it in parallel for each file, parallelizing it for 8 cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ad44793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: .../450k_data/chr18\n",
      "Processing: .../450k_data/chr3\n",
      "Processing: .../450k_data/chr20\n",
      "Processing: .../450k_data/chr17\n",
      "Processing: .../450k_data/chr8\n",
      "Processing: .../450k_data/chr19\n",
      "Processing: .../450k_data/chr15\n",
      "Processing: .../450k_data/chr10\n",
      "Processing: .../450k_data/chr12\n",
      "Processing: .../450k_data/chr16\n",
      "Processing: .../450k_data/chr14\n",
      "Processing: .../450k_data/chr5\n",
      "Processing: .../450k_data/chr22\n",
      "Processing: .../450k_data/chr2\n",
      "Processing: .../450k_data/chr6\n",
      "Processing: .../450k_data/chr7\n",
      "Processing: .../450k_data/chr1\n",
      "Processing: .../450k_data/chr9\n",
      "Processing: .../450k_data/chr13\n",
      "Processing: .../450k_data/chr21\n",
      "Processing: .../450k_data/chr4\n",
      "Processing: .../450k_data/chr11\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "pool = mp.Pool(8)\n",
    "\n",
    "for chromosome in chromosomes:\n",
    "    print (\"Processing:\", chromosome, flush=True)\n",
    "    \n",
    "    parts = glob.glob(f\"{chromosome}/*.part*[0-9].csv.gz\")\n",
    "    \n",
    "    pool.map(\n",
    "        process_and_save_vcf,\n",
    "        parts\n",
    "    )\n",
    "    \n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de73c93f",
   "metadata": {},
   "source": [
    "Let's check if we have no less rows than in original file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7af7759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3414492\r\n"
     ]
    }
   ],
   "source": [
    "!less $path | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ce321e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3414511\r\n"
     ]
    }
   ],
   "source": [
    "!less $processed_path | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01406d99",
   "metadata": {},
   "source": [
    "# Number of unique variants for the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f94c99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of files: 952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.../450k_data/chr18/output.chr18.part14.norm.csv.gz',\n",
       " '.../450k_data/chr18/output.chr18.part7.norm.csv.gz',\n",
       " '.../450k_data/chr18/output.chr18.part1.norm.csv.gz']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "parts = glob.glob(f\".../450k_data/chr*[0-9]/*.part*[0-9].norm.csv.gz\")\n",
    "\n",
    "print (\"Total amount of files:\", len(parts))\n",
    "\n",
    "parts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab4b7cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def get_unique_variants_count(filename):\n",
    "    df = pd.read_csv(filename, compression='gzip')[['chrom', 'pos', 'ref', 'alt']].drop_duplicates()\n",
    "    return filename, df.shape[0]\n",
    "\n",
    "# Multi-processing\n",
    "\n",
    "pool = mp.Pool(8)\n",
    "\n",
    "result = pool.map(\n",
    "    get_unique_variants_count,\n",
    "    parts\n",
    ")\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66d9c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique variants: 1544703\n"
     ]
    }
   ],
   "source": [
    "print (f\"Number of unique variants: {sum(map(lambda x: x[1], result))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "variant_prio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
