{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from collections import defaultdict\n",
    "from ukbb_recessive.regression.regressions import run_regressions, save_table_for_paper, get_formula, get_target_family"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5deeee7",
   "metadata": {},
   "source": [
    "# Create regressions datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../../../../data/tables\"\n",
    "datasets_path = '.../450k/datasets'\n",
    "\n",
    "datasets_dict = {\n",
    "    'Cassa': pd.read_csv(f\"{datasets_path}/Cassa.csv\", sep='\\t'),\n",
    "    'pLI': pd.read_csv(f\"{datasets_path}/PLI.csv\", sep='\\t'),\n",
    "    'Weghorn': pd.read_csv(f\"{datasets_path}/Weghorn-drift.csv\", sep='\\t'),\n",
    "    'Roulette': pd.read_csv(f\"{datasets_path}/Roulette.csv\", sep='\\t'),\n",
    "}\n",
    "\n",
    "# samples of interest: European & non-related without hom and comp_het\n",
    "european_non_rel_samples = (\n",
    "    \".../450k/samples/european_non_related_no_withdrawal_to_include_450k.no_hom_comp_het.txt\"\n",
    ")\n",
    "\n",
    "with open(european_non_rel_samples, 'r') as f:\n",
    "    european_non_rel_samples = [l.strip() for l in f.readlines()]\n",
    "\n",
    "print (f\"Number of european non-related samples without hom and comp_het: {len(european_non_rel_samples)}\\n\")\n",
    "\n",
    "for dataset_name, dataset in datasets_dict.items():\n",
    "    print (f\"Number of samples in {dataset_name}: {datasets_dict[dataset_name].shape[0]}\")\n",
    "    datasets_dict[dataset_name] = dataset[dataset['eid'].astype(str).isin(european_non_rel_samples)].copy()\n",
    "    print (f\"Number of samples in {dataset_name} after filtration: {datasets_dict[dataset_name].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = [\n",
    "    'ID_total', 'Metabolic_ID',  'Blindness',\n",
    "    'Cilia_Kidney', 'Deafness', 'Derm', 'Endocrine',\n",
    "    'Hematologic', 'Immune_system', 'Neuromuscular',\n",
    "    'Skeletal_Craniofacial', 'Metabolic', 'Overlaps'\n",
    "]\n",
    "\n",
    "panel_s_het_list = ['s_het_recessive_' + panel for panel in panels]\n",
    "\n",
    "print (f\"Total amount of panels: \", len(panels), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962b1eb",
   "metadata": {},
   "source": [
    "# Define analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correction for 14: 13 panels + 1 for non-ID\n",
    "\n",
    "# regressions for 13 panels\n",
    "panel_regressions = {\n",
    "    's_hets': panel_s_het_list,\n",
    "    'targets': ['childlessness', 'years_of_edu', 'diagnosis_total_ICD10_cnt_log', 'fluid_intelligence_score', 'is_blond'],\n",
    "    'families': ['binomial', 'gaussian', 'gaussian', 'gaussian', 'binomial'],\n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 14,\n",
    "    'filter_dataset': lambda dataset: dataset\n",
    "}\n",
    "\n",
    "# regressions for ID vs non-ID\n",
    "id_vs_other_regressions = {\n",
    "    's_hets': ['s_het_recessive_AR_without_ID', 's_het_recessive_ID_total'],\n",
    "    'targets': ['childlessness', 'years_of_edu', 'diagnosis_total_ICD10_cnt_log', 'fluid_intelligence_score', 'is_blond'],\n",
    "    'families': ['binomial', 'gaussian', 'gaussian', 'gaussian', 'binomial'],\n",
    "    'genders': ['all'], \n",
    "    'n_tests_correction': 14, \n",
    "    'filter_dataset': lambda dataset: dataset\n",
    "}\n",
    "\n",
    "analyses = {\n",
    "    'panel': panel_regressions,\n",
    "    'id_vs_rest': id_vs_other_regressions\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93250eea",
   "metadata": {},
   "source": [
    "# Generate regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for analysis, analysis_cfg in analyses.items():\n",
    "\n",
    "    all_results = defaultdict(list)\n",
    "\n",
    "    print (f\"Running {analysis} analysis\\n\")\n",
    "\n",
    "    # read analysis config\n",
    "    s_hets = analysis_cfg['s_hets']\n",
    "    targets = analysis_cfg['targets']\n",
    "    families = analysis_cfg['families']\n",
    "    genders = analysis_cfg['genders']   \n",
    "    filter_dataset_func = analysis_cfg['filter_dataset']\n",
    "    n_tests_correction = analysis_cfg['n_tests_correction']\n",
    "     \n",
    "    \n",
    "    # iterate over different s-het datasets\n",
    "    for dataset_key in datasets_dict:\n",
    "        print (\"\\tProcessing\", dataset_key, flush=True)\n",
    "\n",
    "        # iterate over different s-het burdens\n",
    "        for s_het in s_hets:\n",
    "            if not (isinstance(s_het, list) or isinstance(s_het, tuple)) :\n",
    "                s_het = [s_het]\n",
    "\n",
    "            analysis_tag = f'{analysis} regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "            print (f\"\\t\\tRun {analysis_tag}\")\n",
    "\n",
    "            dataset = filter_dataset_func(datasets_dict[dataset_key]).copy()\n",
    "            print (f\"\\t\\t\\tDataset size after filtration: {dataset.shape}\")\n",
    "\n",
    "            regression_result = run_regressions(dataset=dataset, \n",
    "                                                targets=targets, \n",
    "                                                families=families, \n",
    "                                                analysis_tag=analysis_tag, \n",
    "                                                genders=genders, \n",
    "                                                s_het_list=s_het, \n",
    "                                                tab_offset='\\t\\t\\t', \n",
    "                                                n_tests_correction=n_tests_correction)\n",
    "            \n",
    "            all_results[dataset_key].append(regression_result)\n",
    "\n",
    "            print()\n",
    "\n",
    "    all_results = {dataset_key: pd.concat(all_results[dataset_key]) for dataset_key in all_results}\n",
    "\n",
    "    save_table_for_paper(all_results, f\"{output_path}/table_{analysis}_analysis.xlsx\", \n",
    "                         keep_effects=[])\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd380cc",
   "metadata": {},
   "source": [
    "# Significance test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bac7d",
   "metadata": {},
   "source": [
    "Run regression for both AR without ID and ID-only to compare the regression coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = id_vs_other_regressions['targets']\n",
    "families = id_vs_other_regressions['families']\n",
    "\n",
    "target_results = defaultdict(dict)\n",
    "\n",
    "for target, family in zip(targets, families):\n",
    "    print (\"Processing\", target, flush=True)\n",
    "\n",
    "    formula = get_formula(target=target, s_het_list=['s_het_recessive_AR_without_ID', 's_het_recessive_ID_total'])\n",
    "\n",
    "    # run regressions\n",
    "    model = smf.glm(formula = formula, data=datasets_dict['Roulette'].copy(), family=get_target_family(family))\n",
    "    fitted_model = model.fit()\n",
    "    \n",
    "    target_results[target] = fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(target)\n",
    "\n",
    "    print(target_results[target].t_test(\n",
    "        's_het_recessive_AR_without_ID = s_het_recessive_ID_total', use_t=True))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(target)\n",
    "\n",
    "    print(target_results[target].wald_test(\n",
    "        's_het_recessive_AR_without_ID = s_het_recessive_ID_total'))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187e1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "variant_prio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
