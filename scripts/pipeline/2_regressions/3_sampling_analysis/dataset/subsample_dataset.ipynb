{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from ukbb_recessive.regression.regressions import run_regressions, save_table_for_paper, get_formula, get_target_family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regressions datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load datasets for the regression analysis saved on the previous step using script `0_create_dataset.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../../../../../data/tables/sampling/dataset\"\n",
    "datasets_path = '.../450k/datasets/'\n",
    "\n",
    "datasets_dict = {\n",
    "    'Roulette': pd.read_csv(f\"{datasets_path}/Roulette.csv\", sep='\\t')\n",
    "}\n",
    "\n",
    "# samples of interest: European & non-related without hom and comp_het\n",
    "european_non_rel_samples = (\n",
    "    \".../450k/samples/european_non_related_no_withdrawal_to_include_450k.no_hom_comp_het.txt\"\n",
    ")\n",
    "\n",
    "with open(european_non_rel_samples, 'r') as f:\n",
    "    european_non_rel_samples = [l.strip() for l in f.readlines()]\n",
    "\n",
    "print (f\"Number of european non-related samples without hom and comp_het: {len(european_non_rel_samples)}\\n\")\n",
    "\n",
    "for dataset_name, dataset in datasets_dict.items():\n",
    "    print (f\"Number of samples in {dataset_name}: {datasets_dict[dataset_name].shape[0]}\")\n",
    "    datasets_dict[dataset_name] = dataset[dataset['eid'].astype(str).isin(european_non_rel_samples)].copy()\n",
    "    print (f\"Number of samples in {dataset_name}: {datasets_dict[dataset_name].shape[0]}\")\n",
    "\n",
    "    datasets_dict[dataset_name]['diagnosis_secondary_ICD10_cnt_log'] = np.log(datasets_dict[dataset_name]['diagnosis_secondary_ICD10_cnt'])\n",
    "    datasets_dict[dataset_name]['diagnosis_main_ICD10_cnt_log'] = np.log(datasets_dict[dataset_name]['diagnosis_main_ICD10_cnt'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-sample the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We downsample dataset and repeat an analysis for each downsample fraction `n_repeats` times to measure, how big should be the dataset to capture the effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hets = ['s_het_recessive_all', 's_het_recessive_ID_total', 's_het_lof_without_AR']\n",
    "\n",
    "sub_sample_fractions = np.arange(0.1, 1.1, 0.1).tolist()\n",
    "n_repeats = 20\n",
    "\n",
    "# iterate over different covariates\n",
    "for s_het in s_hets:\n",
    "    if not isinstance(s_het, list):\n",
    "        s_het = [s_het]\n",
    "\n",
    "    analysis_tag = f'dataset sampling regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    # iterate over different s-het sources (cassa, weghorn, pli)\n",
    "    # for dataset_key in datasets_dict:\n",
    "    for dataset_key in ['Roulette']:\n",
    "\n",
    "        all_results[dataset_key] = []\n",
    "        \n",
    "        # iterate over different sample fractions\n",
    "        for fraction in sub_sample_fractions:\n",
    "\n",
    "            fraction = round(fraction, 2)\n",
    "\n",
    "            print (\"Processing\", dataset_key, flush=True)\n",
    "            print (fraction)\n",
    "            \n",
    "            # make several repeats\n",
    "            for i in range(n_repeats):\n",
    "\n",
    "                # dataset = datasets_dict[dataset_key].sample(frac=fraction, replace=True)\n",
    "                dataset = datasets_dict[dataset_key].sample(frac=fraction, replace=False)\n",
    "\n",
    "                regression_result = run_regressions(dataset=dataset, \n",
    "                                                    targets=['childlessness'], \n",
    "                                                    families=['binomial'], \n",
    "                                                    analysis_tag=analysis_tag+f\"_frac={fraction}\", \n",
    "                                                    genders=['all'], \n",
    "                                                    s_het_list=s_het)\n",
    "                \n",
    "                all_results[dataset_key] += [regression_result]\n",
    "\n",
    "                if fraction == 1:\n",
    "                    break\n",
    "\n",
    "        all_results[dataset_key] = pd.concat(all_results[dataset_key])\n",
    "    \n",
    "    save_table_for_paper(all_results, f\"{output_path}/table_{analysis_tag.replace(' ', '_')}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbb_recessive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
