{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the details about the processing part done mostly by Hila. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the data by chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the directory with normalized data from previous step (3_normalize_data.ipynb)\n",
    "\n",
    "cd .../450k_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging all the norm.part* files without headers, output stored in .../450k/RAP_output_per_chr/\n",
    "first=1\n",
    "for i in {1..22}; do for f in ./chr$i/output.chr$i.part*.norm.csv.gz; do if [ \"$first\" ]; then zcat \"$f\"; first=; else zcat \"$f\"| tail -n +2; fi; done >.../450k/RAP_output_per_chr/chr$i.all_parts.csv ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f29313",
   "metadata": {},
   "source": [
    "The file `.../450k/samples/ancestry/european_non_related_to_include.txt` is a combination of the output from script `pipeline/1_generate_unrelaed_samples.ipynb` (`./450k/samples/relatedness/related_samples_to_remove_final.txt`) and samples with non-european genetic ancestry (based on data-field `22006`).\n",
    "\n",
    "\n",
    "The file `.../450k/samples/withdrawal_samples.txt` contains samples that need to be withdrew due to revoked consent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an updated list of identifiers (rempve most updated withdrawals)\n",
    "fgrep -vf .../450k/samples/withdrawal_samples.txt .../450k/samples/ancestry/european_non_related_to_include.txt > .../450k/samples/european_non_related_no_withdrawal_to_include.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create updated per-chr files with samples to include\n",
    "for i in {1..22}; do awk -v FS=\",\" 'FNR==NR{arr[$0];next} ($6 in arr)' .../450k/samples/european_non_related_no_withdrawal_to_include.txt .../450k/RAP_output_per_chr/chr$i.all_parts.csv> .../450k/RAP_output_per_chr/chr$i.all_parts_updated_samples.csv; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the header randomly from one of the files:\n",
    "zcat ./chr22/output.chr22.part0.norm.csv.gz|grep chrom > .../450k/RAP_output_per_chr/header.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding header to the individual merged files per chromosome:\n",
    "for i in {1..22}; do cat .../450k/RAP_output_per_chr/header.txt  .../450k/RAP_output_per_chr/chr$i.all_parts_updated_samples.csv > .../450k/RAP_output_per_chr/chr$i.all_parts_final.csv; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing un-needed files:\n",
    "rm -f .../450k/RAP_output_per_chr/*all_parts.csv\n",
    "rm -f .../450k/RAP_output_per_chr/*all_parts_updated_samples.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the annotaion, we need to activate our inhouse research annotation tool.\n",
    "These are the necessary preparations for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make job files for hcdiff (based on .../450k/scripts/vcfPos_forWebAnnot_new.py)\n",
    "for i in {1..22}; do cp .../450k/scripts/vcfPos_forWebAnnot_new.py .../450k/RAP_output_per_chr/files_for_annotation/job_files/hcdiff_${i}.job ; done\n",
    "cd .../450k/RAP_output_per_chr/files_for_annotation/job_files/\n",
    "for f in hcdiff*.job ; do n=$(echo $f | cut -d\".\" -f1 |cut -d\"_\" -f2); sed 's:'number':'${n}':g' ${f} > hcdiff_${n}_ready.py; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make job files for in house annotation (based on .../450k/scripts/annotate_in_house.sh)\n",
    "for i in {1..22}; do cp .../450k/scripts/annotate_in_house.sh .../450k/RAP_output_per_chr/files_for_annotation/job_files/annotate_in_house_${i}.job ; done\n",
    "cd .../450k/RAP_output_per_chr/files_for_annotation/job_files/\n",
    "for f in annotate_in_house*.job ; do n=$(echo $f | cut -d\".\" -f1 |cut -d\"_\" -f4); sed 's:'number':'${n}':g' ${f} > annotate_in_house_${n}_ready.sh; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make job files for running all preparations (based on .../450k/scripts/prepare_for_annotate.py)\n",
    "for i in {1..22}; do cp .../450k/scripts/prepare_for_annotate.py .../450k/RAP_output_per_chr/files_for_annotation/job_files/prepare_for_annotate_${i}.job ; done\n",
    "cd .../450k/RAP_output_per_chr/files_for_annotation/job_files/\n",
    "for f in prepare_for_annotate_*.job ; do n=$(echo $f | cut -d\".\" -f1 |cut -d\"_\" -f4); sed 's:'number':'${n}':g' ${f} > prepare_for_annotate_${n}_ready.py; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sh job files for running all preparations files (based on .../450k/scripts/prepare_for_annotate.sh)\n",
    "for i in {1..22}; do cp .../450k/scripts/prepare_for_annotate.sh .../450k/RAP_output_per_chr/files_for_annotation/job_files/prepare_for_annotate_${i}.sh ; done\n",
    "cd .../450k/RAP_output_per_chr/files_for_annotation/job_files/\n",
    "for f in prepare_for_annotate_*.sh ; do n=$(echo $f | cut -d\".\" -f1 |cut -d\"_\" -f4); sed 's:'number':'${n}':g' ${f} > prepare_for_annotate_${n}_ready.sh; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the .../450k/scripts/prepare_for_annotate_X_ready.sh files\n",
    "cd .../450k/RAP_output_per_chr/files_for_annotation/job_files/\n",
    "for i in {1..22}; do sbatch prepare_for_annotate_${i}_ready.sh; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation runs for each chromosome separately, using a template script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make job files for running all annotations (based on .../450k/scripts/annotate_pandas.py)\n",
    "for i in {1..22}; do cp .../450k/scripts/annotate_pandas.py .../450k/plp_selection/job_files/annotate_pandas_${i}.job ; done\n",
    "cd .../450k/plp_selection/job_files/\n",
    "for f in annotate_pandas_*.job ; do n=$(echo $f | cut -d\".\" -f1 |cut -d\"_\" -f3); sed 's:'number':'${n}':g' ${f} > annotate_pandas_${n}_ready.py; done\n",
    "for i in {1..22}; do python annotate_pandas_${i}_ready.py; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLPs selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLPs selection runs for each chromosome separately, using a template script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make job files for running all plps selection (based on .../450k/scripts/select_plps_pandas.py)\n",
    "for i in {1..22}; do cp .../450k/scripts/select_plps_pandas.py .../450k/plp_selection/job_files/select_plps_pandas_${i}.job ; done\n",
    "cd .../450k/plp_selection/job_files/\n",
    "for f in select_plps_pandas_*.job ; do n=$(echo $f | cut -d\".\" -f1 |cut -d\"_\" -f4); sed 's:'number':'${n}':g' ${f} > select_plps_pandas_${n}_ready.py; done\n",
    "for i in {1..22}; do python select_plps_pandas_${i}_ready.py; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit presumable plps\n",
    "#Notice there is a manual part inside this script\n",
    "python .../450k/scripts/edit_plps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b8e97",
   "metadata": {},
   "source": [
    "# PLPs statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## file, that contains all PLPs found in the cohort\n",
    "all_plps_file = (\n",
    "    \".../450k/plp_selection/basic/new_gene_names/new_freq/new_relatedness/\"\n",
    "    \"all_chr_total_presumable_plps_HFE_final_sorted.txt\"\n",
    ")\n",
    "\n",
    "plps = pd.read_csv(all_plps_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de26d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditions tier 1- \"safe tier\"\n",
    "cond_clinvar = ((plps['clinvar'].str.contains(\"athogenic\")) & (plps[~(plps['clinvar_stars']==\" \")]['clinvar_stars']>=2))\n",
    "cond_vkgl = (plps['vkgl']==\"LP\")     \n",
    "\n",
    "tier_1_cond = (cond_clinvar | cond_vkgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f143e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conditions tier 2- \"rare LOF\"\n",
    "cond_region = ((plps['region'].str.contains(\"CANONICAL\")) | (plps['region']==\"EXON_REGION\"))\n",
    "cond_synonymous = (~plps['synonymous'])\n",
    "variant_types = [\"stop_gained\",\"frameshift\",\"splice_donor\",\"splice_acceptor\"]\n",
    "cond_variant_type = (plps['Protein Effect'].str.contains('|'.join(variant_types),na=False))\n",
    "\n",
    "cond_lof = (cond_region & cond_synonymous & cond_variant_type)\n",
    "cond_freq_var = (plps['gnomAD-E_AF']<1)\n",
    "\n",
    "cond_clinvar_not = ~(plps['clinvar'].str.contains(\"enign\") & (plps[~(plps['clinvar_stars']==\" \")]['clinvar_stars']>=2))\n",
    "cond_vkgl_not = ~(plps['vkgl']==\"LB\")\n",
    "\n",
    "tier_2_cond = (cond_lof & cond_freq_var & cond_clinvar_not & cond_vkgl_not)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2be473",
   "metadata": {},
   "outputs": [],
   "source": [
    "plps['tier'] = \"missense\"\n",
    "\n",
    "plps.loc[tier_2_cond, 'tier'] = 'rare LoF'\n",
    "plps.loc[tier_1_cond, 'tier'] = 'ClinVar/VKGL'\n",
    "\n",
    "plps['tier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77cadc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
