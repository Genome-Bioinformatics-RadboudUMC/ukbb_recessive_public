{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from ukbb_recessive.regression.regressions import run_regressions, save_table_for_paper, get_formula, get_target_family"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5deeee7",
   "metadata": {},
   "source": [
    "# Load regressions datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d59ed4",
   "metadata": {},
   "source": [
    "First, we load datasets for the regression analysis saved on the previous step using script `0_create_dataset.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = '.../datasets'\n",
    "\n",
    "datasets_dict = {\n",
    "    'Cassa': pd.read_csv(f\"{datasets_path}/Cassa.csv\", sep='\\t'),\n",
    "    'pLI': pd.read_csv(f\"{datasets_path}/PLI.csv\", sep='\\t'),\n",
    "    'Weghorn': pd.read_csv(f\"{datasets_path}/Weghorn-drift.csv\", sep='\\t'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1bb42",
   "metadata": {},
   "source": [
    "Here are all s_het-based genetic burdens, calculated based on different gene sets and variants (PLPs or singleton LOFs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6024d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datasets_dict['Cassa'].columns:\n",
    "    if col[:5] == 's_het':\n",
    "        print (col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93250eea",
   "metadata": {},
   "source": [
    "# Generate regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e8866",
   "metadata": {},
   "source": [
    "We define all phenotypes (targets), that we would like to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=['childlessness', 'any_education_including_none', 'is_blond', \n",
    "         'fluid_intelligence_score','higher_education_including_none']\n",
    "\n",
    "families=['binomial', 'binomial', 'binomial', \n",
    "          'gaussian', 'binomial']\n",
    "\n",
    "genders=['all']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e3b96c2",
   "metadata": {},
   "source": [
    "## All samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c91aad",
   "metadata": {},
   "source": [
    "We define all combinations of s-het burdens that we would like to check for the association with phenotypes and run the regressions for all samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fabb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hets = ['s_het_recessive_all', 's_het_lof_without_AR', 's_het_lof_AR', ['s_het_recessive_all', 's_het_lof_without_AR'], 's_het_recessive_without_high_s_het']\n",
    "\n",
    "for s_het in s_hets:\n",
    "    if not isinstance(s_het, list):\n",
    "        s_het = [s_het]\n",
    "\n",
    "    analysis_tag = f'basic regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for dataset_key in datasets_dict:\n",
    "\n",
    "        print (\"Processing\", dataset_key, flush=True)\n",
    "\n",
    "        regression_result = run_regressions(dataset=datasets_dict[dataset_key], \n",
    "                                            targets=targets, \n",
    "                                            families=families, \n",
    "                                            analysis_tag=analysis_tag, \n",
    "                                            genders=genders, \n",
    "                                            s_het_list=s_het)\n",
    "        \n",
    "        all_results[dataset_key] = regression_result\n",
    "\n",
    "    save_table_for_paper(all_results, f\"../../../../data/tables/table_{analysis_tag.replace(' ', '_')}.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3e68d7f",
   "metadata": {},
   "source": [
    "## Exclude LoF carriers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247397ce",
   "metadata": {},
   "source": [
    "To ensure, that our resuls are not confounded by the LoF carriers in other genes, we exclude all those carriers and repeat the analysis for PLPs in all recessive genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3621dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hets = ['s_het_recessive_all']\n",
    "\n",
    "for s_het in s_hets:\n",
    "    if not isinstance(s_het, list):\n",
    "        s_het = [s_het]\n",
    "\n",
    "    analysis_tag = f'basic regressions on {str(s_het)} without LoF carriers'.replace(\"'\", '')\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for dataset_key in datasets_dict:\n",
    "\n",
    "        print (\"Processing\", dataset_key, flush=True)\n",
    "\n",
    "        # exclude carriers\n",
    "        dataset = datasets_dict[dataset_key]\n",
    "        print (\"Number of LoF carriers in non-recessive genes:\", dataset['has_mutation_lof_without_AR'].fillna(0).sum())\n",
    "        dataset = dataset[dataset['has_mutation_lof_without_AR'].fillna(0) != 1]\n",
    "\n",
    "        regression_result = run_regressions(dataset=dataset, \n",
    "                                            targets=targets, \n",
    "                                            families=families, \n",
    "                                            analysis_tag=analysis_tag, \n",
    "                                            genders=genders, \n",
    "                                            s_het_list=s_het)\n",
    "        \n",
    "        all_results[dataset_key] = regression_result\n",
    "\n",
    "    save_table_for_paper(all_results, f\"../../../../data/tables/table_{analysis_tag.replace(' ', '_')}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619c697",
   "metadata": {},
   "source": [
    "# Correction for other covariants: ICD and infertility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35feeb04",
   "metadata": {},
   "source": [
    "To ensure, that our results are not confounded by infertility or other diseases, we run the regressions with new covariates like infertility and ICD diagnosis counts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e20751",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_phenotypes = ['diagnosis_main_ICD10_cnt', 'diagnosis_secondary_ICD10_cnt', 'diagnosis_total_ICD10_cnt', 'ICD_infertility']\n",
    "\n",
    "s_hets = [['s_het_recessive_all', correction_phenotype] for correction_phenotype in correction_phenotypes] + ['s_het_recessive_all']\n",
    "print (s_hets)\n",
    "        \n",
    "all_results = {}\n",
    "\n",
    "# iterate over different s-het sources (cassa, weghorn, pli)\n",
    "for dataset_key in datasets_dict:\n",
    "\n",
    "    all_results[dataset_key] = []\n",
    "\n",
    "    # iterate over different covariates\n",
    "    for s_het in s_hets:\n",
    "        if not isinstance(s_het, list):\n",
    "            s_het = [s_het]\n",
    "\n",
    "        analysis_tag = f'basic regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "        print (analysis_tag)\n",
    "\n",
    "\n",
    "        regression_result = run_regressions(dataset=datasets_dict[dataset_key], \n",
    "                                            targets=['childlessness'], \n",
    "                                            families=['binomial'], \n",
    "                                            analysis_tag=analysis_tag, \n",
    "                                            genders=['all'], \n",
    "                                            s_het_list=s_het)\n",
    "        \n",
    "        all_results[dataset_key] += [regression_result]\n",
    "\n",
    "\n",
    "    all_results[dataset_key] = pd.concat(all_results[dataset_key])\n",
    "    \n",
    "save_table_for_paper(all_results, f\"../../../../data/tables/table_basic_regressions_with_covariates.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf6700",
   "metadata": {},
   "source": [
    "# Preliminary regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b521606",
   "metadata": {},
   "source": [
    "Here we tried to look into the effect of being a carrier of PLP in recessive gene without taking into account the selection constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hets = ['has_mutation_recessive_all', 'mutations_cnt_recessive_all', 'has_mutation_lof_all']\n",
    "targets = ['childlessness']\n",
    "families = ['binomial']\n",
    "genders = ['all']\n",
    "\n",
    "\n",
    "all_results = defaultdict(list)\n",
    "    \n",
    "for dataset_key in datasets_dict:\n",
    "    print (\"Processing\", dataset_key, flush=True)\n",
    "\n",
    "    for s_het in s_hets:\n",
    "        if not isinstance(s_het, list):\n",
    "            s_het = [s_het]\n",
    "\n",
    "        analysis_tag = f'preliminary regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "        print (f\"Run {analysis_tag}\")\n",
    "\n",
    "        regression_result = run_regressions(dataset=datasets_dict[dataset_key], \n",
    "                                            targets=targets, \n",
    "                                            families=families, \n",
    "                                            analysis_tag=analysis_tag, \n",
    "                                            genders=genders, \n",
    "                                            s_het_list=s_het)\n",
    "        \n",
    "        all_results[dataset_key].append(regression_result)\n",
    "\n",
    "    all_results[dataset_key] = pd.concat(all_results[dataset_key])\n",
    "\n",
    "save_table_for_paper(all_results, f\"../../../../data/tables/table_preliminary_regressions.xlsx\", keep_effects=s_hets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hets = ['has_mutation_recessive_all', 'mutations_cnt_recessive_all']\n",
    "targets = ['childlessness']\n",
    "families = ['binomial']\n",
    "genders = ['all']\n",
    "\n",
    "\n",
    "all_results = defaultdict(list)\n",
    "    \n",
    "for dataset_key in datasets_dict:\n",
    "    print (\"Processing\", dataset_key, flush=True)\n",
    "\n",
    "    # exclude carriers\n",
    "    dataset = datasets_dict[dataset_key]\n",
    "    dataset = dataset[dataset['has_mutation_lof_without_AR'].fillna(0) != 1]\n",
    "\n",
    "    for s_het in s_hets:\n",
    "        if not isinstance(s_het, list):\n",
    "            s_het = [s_het]\n",
    "\n",
    "        analysis_tag = f'preliminary regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "        print (f\"Run {analysis_tag}\")\n",
    "\n",
    "        regression_result = run_regressions(dataset=dataset, \n",
    "                                            targets=targets, \n",
    "                                            families=families, \n",
    "                                            analysis_tag=analysis_tag, \n",
    "                                            genders=genders, \n",
    "                                            s_het_list=s_het)\n",
    "        \n",
    "        all_results[dataset_key].append(regression_result)\n",
    "\n",
    "    all_results[dataset_key] = pd.concat(all_results[dataset_key])\n",
    "\n",
    "save_table_for_paper(all_results, f\"../../../../data/tables/table_preliminary_regressions_without_LoF_carriers.xlsx\", keep_effects=s_hets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed370635",
   "metadata": {},
   "source": [
    "## Sub-sample the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df7b45b",
   "metadata": {},
   "source": [
    "We downsample dataset and repeat an analysis for each downsample fraction `n_repeats` times to measure, how big should be the dataset to capture the effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739acced",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hets = ['s_het_recessive_all', 's_het_lof_without_AR']\n",
    "\n",
    "sub_sample_fractions = np.arange(0.1, 1.1, 0.1).tolist()\n",
    "n_repeats = 20\n",
    "\n",
    "# iterate over different covariates\n",
    "for s_het in s_hets:\n",
    "    if not isinstance(s_het, list):\n",
    "        s_het = [s_het]\n",
    "\n",
    "    analysis_tag = f'reduced samples regressions on {str(s_het)}'.replace(\"'\", '')\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    # iterate over different s-het sources (cassa, weghorn, pli)\n",
    "    for dataset_key in datasets_dict:\n",
    "\n",
    "        all_results[dataset_key] = []\n",
    "        \n",
    "        # iterate over different sample fractions\n",
    "        for fraction in sub_sample_fractions:\n",
    "\n",
    "            fraction = round(fraction, 2)\n",
    "\n",
    "            print (\"Processing\", dataset_key, flush=True)\n",
    "            print (fraction)\n",
    "            \n",
    "            # make several repeats\n",
    "            for i in range(n_repeats):\n",
    "\n",
    "                dataset = datasets_dict[dataset_key].sample(frac=fraction)\n",
    "\n",
    "                regression_result = run_regressions(dataset=dataset, \n",
    "                                                    targets=['childlessness'], \n",
    "                                                    families=['binomial'], \n",
    "                                                    analysis_tag=analysis_tag+f\"_frac={fraction}\", \n",
    "                                                    genders=['all'], \n",
    "                                                    s_het_list=s_het)\n",
    "                \n",
    "                all_results[dataset_key] += [regression_result]\n",
    "\n",
    "                if fraction == 1:\n",
    "                    break\n",
    "\n",
    "        all_results[dataset_key] = pd.concat(all_results[dataset_key])\n",
    "    \n",
    "    save_table_for_paper(all_results, f\"../../../../data/tables/table_{analysis_tag.replace(' ', '_')}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81e64c",
   "metadata": {},
   "source": [
    "# Significance test PLPs vs LoFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f55e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_hets = ['s_het_recessive_all', 's_het_lof_without_AR']\n",
    "\n",
    "targets=['childlessness']\n",
    "\n",
    "families=['binomial', 'binomial', 'binomial']\n",
    "\n",
    "all_results = defaultdict(dict)\n",
    "\n",
    "for target, family in zip(targets, families):\n",
    "    print (\"Processing\", target, flush=True)\n",
    "\n",
    "    for dataset_key in ['Weghorn']:\n",
    "        print (\"\\tProcessing\", dataset_key, flush=True)\n",
    "\n",
    "        dataset_subset = datasets_dict[dataset_key].copy()\n",
    "\n",
    "        formula = get_formula(target=target, s_het_list=s_hets)\n",
    "\n",
    "        # run regressions\n",
    "        model = smf.glm(formula = formula, data=dataset_subset, family=get_target_family(family))\n",
    "        fitted_model = model.fit()\n",
    "        \n",
    "        all_results[target][dataset_key] = fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e46a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    odds_ratios =  np.round(np.exp(all_results[target]['Weghorn'].params), 2)\n",
    "\n",
    "    print (f\"Target = {target}, OR {s_hets[0]}={odds_ratios[s_hets[0]]}, OR {s_hets[1]}={odds_ratios[s_hets[1]]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682907cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    print(target)\n",
    "\n",
    "    print(all_results[target]['Weghorn'].t_test(\n",
    "        's_het_recessive_all = s_het_lof_without_AR', use_t=True))\n",
    "    \n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "variant_prio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
